{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Packages for loading, cleaning, visualization, and analysis\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import string as st\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Class Exercise  -  Save the Cleaned Data Frame\n",
    "\n",
    "Copy the cells from your Data Engineering 3 - Data Cleaning notebook to this notebook. Only copy the cells that you use to clean the data (i.e., if you use imputation rather than row deletion copy the imputation cells and not the row deletion cells). \n",
    "\n",
    "Run the code in the cells and then save your results, the cleaned data frame, to your local or cloud storage. \n",
    "\n",
    "Read the data to validate that you correctly saved your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I have my own function that will pull each year of the train data in a panda df\n",
    "# You pass a directory and it returns a list of pandas dataframes\n",
    "def getListDataFrames(path):\n",
    "    # initialize an empty list\n",
    "    csvs = list()\n",
    "    # Get all the files in the directory\n",
    "    all_files = os.listdir(path)\n",
    "    # Iterate across each of the files in the Data folder\n",
    "    for fileName in all_files:\n",
    "        # Get the full path name\n",
    "        fileToPull = path + fileName\n",
    "        # Read in the data at that location\n",
    "        filesOfInterest = pd.read_csv(fileToPull, low_memory = False, encoding='ISO-8859-1')\n",
    "        csvs.append(filesOfInterest)\n",
    "    return csvs\n",
    "\n",
    "# Here is the list of 16 pandas dataframes corresponding to 2001 thru 2016\n",
    "listOfAccidents = getListDataFrames('/Users/mead/Fall2017/DonBrown-DS6001/InClass1/Data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate the pandas together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51623, 154)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = pd.concat(listOfAccidents, ignore_index = True)\n",
    "acc_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the Narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 1\n",
    "# # Produce a function to add all of the Narratives together\n",
    "# # Takes the index of the NARR1 column as input alongside the dataframe of interest. \n",
    "# # It outputs the full Narrative column\n",
    "# def combineNARR(NARR1index, dataFrme):\n",
    "# # Initialize an empty list of all narratives\n",
    "#     allAccs = list()\n",
    "#     # Iterate across every row\n",
    "#     for acc in range(len(dataFrme.index)):\n",
    "#         # Initialize an empty list of each row's narrative\n",
    "#         fullNarr = list()\n",
    "#         # Iterate across every NARR column\n",
    "#         for narr in range(15):\n",
    "#             index = narr + NARR1index[0]\n",
    "#             # Keep track of the value in that NARR column for that row\n",
    "#             narrElement = str(dataFrme.iloc[acc, index])\n",
    "#             fullNarr.append(narrElement)\n",
    "#         allAccs.append(fullNarr)\n",
    "#     return allAccs\n",
    "\n",
    "# # This is the which function which keeps track of where NARR1 is\n",
    "# which = lambda lst:list(np.where(lst)[0])\n",
    "# NARR1index = which([name == 'NARR1' for name in acc_df.columns])\n",
    "\n",
    "# # Run the function -- output is a list of lists\n",
    "# newColumn = combineNARR(NARR1index, acc_df)\n",
    "\n",
    "# # 2\n",
    "# # Combine all the NARR together for each row. Make sure to remove the NAs\n",
    "# Narratives = [''.join([sentence for sentence in NARR if sentence != 'nan']) for NARR in newColumn]\n",
    "# # Add this as a new column for the accidents df\n",
    "# acc_df['Narrative'] = pd.Series(Narratives, index=acc_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP TRAIN 292-16 (86 LOADS, 26 EMPTIES, 12,342 EGT) INCLUDING 15 LOADS ANHYDROUS AMMONIA; 10 LOADS LP\n",
      "G AND 11 LOADS STYRENE MONOMER INHIBITED, DERAILED 31 CARS, ALL ON THEIR SIDES, RESULTING IN HAZMAT\n",
      "RELEASE FROM ELEVEN CARS (SEE APPENDED LIST) RESULTING IN SPILL OF APPROXIMATELY 590 TONS.  EVACUATI\n",
      "ON OF APPROXIMATELY 20 HOMES IN A HALF-MILE RADIUS IMMEDIATELY EAST OF THE DERAILMENT SITE AND REMAI\n",
      "NS IN EFFECT AS OF 2/27/02.  ONE FATALITY TO A MINOT, ND RESIDENT RESULTED DURING VOLUNTARY EVACUATI\n",
      "ON.  APPROXIMATELY 1,000-2,000 PEOPLE WERE SEEN AND EVALUATED AT HOSPITALS AND CLINICS WITH SOME BEI\n",
      "NG TREATED AND/OR ADMITTED INTO THE HOSPITAL.   EMERGENCY RESPONSE DISPATCHED, COMPANY PERSONNEL AS\n",
      "WELL AS NTSB AND FRA PERSONNEL AT SITE.  STATIONARY COMMAND CENTER SET UP AT LOCAL FIRE STATION AND\n",
      "A MOBILE COMMAND CENTER NEAREST DERAILMENT SITE HAS BEEN SET UP.  FIRE DEPARTMENT RESPONDED AND HOSE\n",
      "D DOWN HAZMAT CARS.  SPAN OF DERAILMENT SITE TOTALED 475 FEET.  SINGLE MAIN CWR TRACK, CLASS 3, 40 M\n",
      "PH.  HULCHER RERAILED CARS.  SERVICE RESUMED AT APPROXIMATELY 0600 CST ON 1/23/02.  CONDUCTOR REPORT\n",
      "ED BEING INJURED DUE TO CHEMICAL EXPOSURE.  NO INJURIES SUSTAINED BY ANY CONTRACTOR PERSONNEL DURING\n",
      "THE CLEAN-UP PROCESS.  NTSB PERSONNEL ON SITE AND INVESTIGATING CAUSE.  CAUSE UNDER INVESTIGATION.\n",
      "FRA FORMS 6180.55A TO BE PROVIDED AS INFORMATION IS RECEIVED.   7/19/06 Ã»UPDATED CAUSE TO T215- JOI\n",
      "NT BAR BROKEN (NON-INSULATED).  THE TOTAL NUMBER OF OTHERS NONFATAL IS ACTUALLY 1440.   ALL ELEVEN C\n"
     ]
    }
   ],
   "source": [
    "# Join the narrative and put them in a list\n",
    "\n",
    "def join_narratives(DF):\n",
    "    '''With the input of the accident dataframe\n",
    "    merge the narrative columns into a single narrative\n",
    "    and return a list of these single narratives for each\n",
    "    accident report in the dataframe. '''\n",
    "    narrlist = []\n",
    "    for i in range(0,15):\n",
    "        a = str(i+1)\n",
    "        narrlist.append('NARR'+ a)\n",
    "    RailNarr = DF.loc[:, narrlist]\n",
    "    Narratives = []\n",
    "    for i, _ in enumerate(RailNarr[\"NARR1\"]):\n",
    "#         print(i)\n",
    "        NarrativeList = RailNarr.iloc[i]\n",
    "        Anarrative = \"\"\n",
    "        for narr in NarrativeList:\n",
    "            if pd.isnull(narr):\n",
    "                break\n",
    "            else:\n",
    "                if(i == 4320):\n",
    "                    print(narr)\n",
    "                Anarrative += str(narr.encode('ascii', 'ignore').decode('ascii'))\n",
    "        Narratives.append(Anarrative)\n",
    "    return Narratives\n",
    "\n",
    "newColumn = join_narratives(acc_df)\n",
    "\n",
    "# Add this as a new column for the accidents df\n",
    "acc_df['Narrative'] = newColumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop old NARR columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop old narrative columns\n",
    "narrList = []\n",
    "for i in range(0,15):\n",
    "    a = str(i + 1)\n",
    "    narrList.append('NARR' + a)\n",
    "acc_df.drop(narrList, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing the duplicates\n",
    "acc_clean_df = acc_df[(acc_df['JOINTCD'] == 1) & (acc_df['TYPE'] != 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51623, 140)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38167, 140)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_clean_df = acc_clean_df.dropna(axis = 1, thresh = (38167-1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38167, 88)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This class imputes the missing values as\n",
    "# (1) most frequent if the variable is categorical \n",
    "# (2) mean if the variable is real (floating point)\n",
    "# (3) median if the variable is an integer \n",
    "\n",
    "# Here is a class that will provide imputation\n",
    "# This is an extension by D.Brown to sveitser, 2014 https://stackoverflow.com/users/469992/sveitser\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "        \n",
    "        Columns of dtype floating point are imputed with the mean.\n",
    "\n",
    "        Columns of other types are imputed with median of the column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') \n",
    "                               else X[c].mean() if X[c].dtype == np.dtype('f')\n",
    "                                else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_clean_df = DataFrameImputer().fit_transform(acc_clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acc_clean_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types: \n",
      "Derailment                   27429\n",
      "Other impacts                 4321\n",
      "Other (described in narr)     2127\n",
      "Side collision                1603\n",
      "Obstruction                    991\n",
      "Raking collision               720\n",
      "fire/violent rupture           454\n",
      "Rearend collision              298\n",
      "Head on collision              125\n",
      "Broken train collision          80\n",
      "Explosive-detonation            14\n",
      "RR Grade Crossing                5\n",
      "Name: TYPE, dtype: int64\n",
      "\n",
      "Weather: \n",
      "clear     25307\n",
      "cloudy     8757\n",
      "rain       2738\n",
      "snow        856\n",
      "fog         431\n",
      "sleet        78\n",
      "Name: WEATHER, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# REPLACING CATEGORICAL VARIABLES\n",
    "# Now to actually go in and make replacements for all of these values \n",
    "# you can go in and use .replace()\n",
    "acc_clean_df[\"TYPE\"] = acc_clean_df['TYPE'].replace(range(1,14),['Derailment', \n",
    "    'Head on collision', 'Rearend collision', 'Side collision', 'Raking collision', \n",
    "    'Broken train collision', 'Hwy-rail crossing', 'RR Grade Crossing', 'Obstruction', \n",
    "    'Explosive-detonation', 'fire/violent rupture', 'Other impacts', \n",
    "    'Other (described in narr)'])\n",
    "# Or you can go in and use a dictionary\n",
    "#map_typeq = {1:'Freight', '1':'Freight'}\n",
    "#acc_clean_df['TYPEQ'] = acc_clean_df.map(map_typeq)\n",
    "print(\"Types: \\n\" + str(acc_clean_df[\"TYPE\"].value_counts()))\n",
    "\n",
    "# Doing the same thing  but for weather\n",
    "acc_clean_df[\"WEATHER\"] = acc_clean_df['WEATHER'].replace(range(1,7),['clear', \n",
    "    'cloudy', 'rain', 'fog', 'sleet', 'snow'])\n",
    "print(\"\\nWeather: \\n\" + str(acc_clean_df[\"WEATHER\"].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can't use CSV because of commas in the Narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([    0,     1,     2,     3,     4,     5,     7,     8,     9,\n",
      "               10,\n",
      "            ...\n",
      "            51611, 51612, 51613, 51614, 51616, 51617, 51618, 51619, 51621,\n",
      "            51622],\n",
      "           dtype='int64', length=38167)\n"
     ]
    }
   ],
   "source": [
    "print(acc_clean_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now save the Narrative\n",
    "# First create dictionary of Narratives\n",
    "# Note: JSON doesn't allow integer values for indices\n",
    "\n",
    "str_index = [str(x) for x in acc_clean_df.index]\n",
    "Narrative_dict = dict(zip(str_index, acc_clean_df.Narrative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38167"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Narrative_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_clean_df.index[878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREW MEMBER FAILED TO LINE SWITCH OF THE CROSSOVER, TRAILED THROUGH THE SWITCH RESULTING IN A DERAILMENT WHEN MOVEMENT WAS REVERSED.'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Narrative_dict['1196']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "path = '/Users/mead/Fall2017/DonBrown-DS6001/InClass1/'\n",
    "file = 'TrainNarratives.txt'\n",
    "with open(path+file, 'w') as destination:\n",
    "    json.dump(Narrative_dict, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38167, 87)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_clean_df.to_csv('/Users/mead/Fall2017/DonBrown-DS6001/InClass1/FullCleanedAdrian.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
